{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "676b9298",
   "metadata": {},
   "source": [
    "# JAX & FLAX\n",
    "\n",
    "> **Author**: Gustavo L. F. Walbon / **Date**: July 2022.\n",
    "\n",
    "In this work we will have the inference of resnet18 with Jax engines.\n",
    "\n",
    "## Objective\n",
    "_In the fourth project you will have to implement the ResNet-18 model using JAX and Flax libraries for inference only. The FLAX library, discussed in the second lecture, provides primitives to stack multiple kinds of layers in order to form a neural network architecture._\n",
    "\n",
    "_After you have implemented the model and loaded the weights, it is time to test your code on a few test images. You may use the images provided in [5](https://github.com/MO436-MC934/work). Finally, you job is to obtain the maximum amount of performance improvement from your network using JAX transformations: jit, vmap, pmap, etc. You may use your CPU, GPU or TPU (in Google Collab). In the end, you should write a report (PDF) describing how you implemented your model, which transformations you applied and why. If you could not apply some transformations, discuss the problems you found while trying to use it. Finally, do a performance analysis showing how fast your model has become compared to the non-transformed model (tables and graphs are welcome)._\n",
    "\n",
    "_Reference: https://github.com/MO436-MC934/notebooks/wiki/5.JAX-Library_\n",
    "\n",
    "### Loading Resnet18\n",
    "Pre-trained network is used to see the weights of kernel and bias of Resnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3777b84a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Tensor: 'resnetv15_conv0_weight'                      shape=(64, 3, 7, 7)\n",
      "- Tensor: 'resnetv15_batchnorm0_gamma'                  shape=(64,)\n",
      "- Tensor: 'resnetv15_batchnorm0_beta'                   shape=(64,)\n",
      "- Tensor: 'resnetv15_batchnorm0_running_mean'           shape=(64,)\n",
      "- Tensor: 'resnetv15_batchnorm0_running_var'            shape=(64,)\n",
      "- Tensor: 'resnetv15_stage1_conv0_weight'               shape=(64, 64, 3, 3)\n",
      "- Tensor: 'resnetv15_stage1_batchnorm0_gamma'           shape=(64,)\n",
      "- Tensor: 'resnetv15_stage1_batchnorm0_beta'            shape=(64,)\n",
      "- Tensor: 'resnetv15_stage1_batchnorm0_running_mean'    shape=(64,)\n",
      "- Tensor: 'resnetv15_stage1_batchnorm0_running_var'     shape=(64,)\n",
      "- Tensor: 'resnetv15_stage1_conv1_weight'               shape=(64, 64, 3, 3)\n",
      "- Tensor: 'resnetv15_stage1_batchnorm1_gamma'           shape=(64,)\n",
      "- Tensor: 'resnetv15_stage1_batchnorm1_beta'            shape=(64,)\n",
      "- Tensor: 'resnetv15_stage1_batchnorm1_running_mean'    shape=(64,)\n",
      "- Tensor: 'resnetv15_stage1_batchnorm1_running_var'     shape=(64,)\n",
      "- Tensor: 'resnetv15_stage1_conv2_weight'               shape=(64, 64, 3, 3)\n",
      "- Tensor: 'resnetv15_stage1_batchnorm2_gamma'           shape=(64,)\n",
      "- Tensor: 'resnetv15_stage1_batchnorm2_beta'            shape=(64,)\n",
      "- Tensor: 'resnetv15_stage1_batchnorm2_running_mean'    shape=(64,)\n",
      "- Tensor: 'resnetv15_stage1_batchnorm2_running_var'     shape=(64,)\n",
      "- Tensor: 'resnetv15_stage1_conv3_weight'               shape=(64, 64, 3, 3)\n",
      "- Tensor: 'resnetv15_stage1_batchnorm3_gamma'           shape=(64,)\n",
      "- Tensor: 'resnetv15_stage1_batchnorm3_beta'            shape=(64,)\n",
      "- Tensor: 'resnetv15_stage1_batchnorm3_running_mean'    shape=(64,)\n",
      "- Tensor: 'resnetv15_stage1_batchnorm3_running_var'     shape=(64,)\n",
      "- Tensor: 'resnetv15_stage2_conv2_weight'               shape=(128, 64, 1, 1)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm2_gamma'           shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm2_beta'            shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm2_running_mean'    shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm2_running_var'     shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_conv0_weight'               shape=(128, 64, 3, 3)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm0_gamma'           shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm0_beta'            shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm0_running_mean'    shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm0_running_var'     shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_conv1_weight'               shape=(128, 128, 3, 3)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm1_gamma'           shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm1_beta'            shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm1_running_mean'    shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm1_running_var'     shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_conv3_weight'               shape=(128, 128, 3, 3)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm3_gamma'           shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm3_beta'            shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm3_running_mean'    shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm3_running_var'     shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_conv4_weight'               shape=(128, 128, 3, 3)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm4_gamma'           shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm4_beta'            shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm4_running_mean'    shape=(128,)\n",
      "- Tensor: 'resnetv15_stage2_batchnorm4_running_var'     shape=(128,)\n",
      "- Tensor: 'resnetv15_stage3_conv2_weight'               shape=(256, 128, 1, 1)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm2_gamma'           shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm2_beta'            shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm2_running_mean'    shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm2_running_var'     shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_conv0_weight'               shape=(256, 128, 3, 3)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm0_gamma'           shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm0_beta'            shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm0_running_mean'    shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm0_running_var'     shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_conv1_weight'               shape=(256, 256, 3, 3)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm1_gamma'           shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm1_beta'            shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm1_running_mean'    shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm1_running_var'     shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_conv3_weight'               shape=(256, 256, 3, 3)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm3_gamma'           shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm3_beta'            shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm3_running_mean'    shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm3_running_var'     shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_conv4_weight'               shape=(256, 256, 3, 3)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm4_gamma'           shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm4_beta'            shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm4_running_mean'    shape=(256,)\n",
      "- Tensor: 'resnetv15_stage3_batchnorm4_running_var'     shape=(256,)\n",
      "- Tensor: 'resnetv15_stage4_conv2_weight'               shape=(512, 256, 1, 1)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm2_gamma'           shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm2_beta'            shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm2_running_mean'    shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm2_running_var'     shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_conv0_weight'               shape=(512, 256, 3, 3)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm0_gamma'           shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm0_beta'            shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm0_running_mean'    shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm0_running_var'     shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_conv1_weight'               shape=(512, 512, 3, 3)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm1_gamma'           shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm1_beta'            shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm1_running_mean'    shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm1_running_var'     shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_conv3_weight'               shape=(512, 512, 3, 3)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm3_gamma'           shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm3_beta'            shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm3_running_mean'    shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm3_running_var'     shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_conv4_weight'               shape=(512, 512, 3, 3)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm4_gamma'           shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm4_beta'            shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm4_running_mean'    shape=(512,)\n",
      "- Tensor: 'resnetv15_stage4_batchnorm4_running_var'     shape=(512,)\n",
      "- Tensor: 'resnetv15_dense0_weight'                     shape=(1000, 512)\n",
      "- Tensor: 'resnetv15_dense0_bias'                       shape=(1000,)\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx import numpy_helper\n",
    "\n",
    "model = onnx.load(\"resnet18.onnx\")\n",
    "\n",
    "for initializer in model.graph.initializer:\n",
    "    array = numpy_helper.to_array(initializer)\n",
    "    print(f\"- Tensor: {initializer.name!r:45} shape={array.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53960ad8",
   "metadata": {},
   "source": [
    "With that the next step is to create the dicionary with the same shape to be used in the interference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9117e238",
   "metadata": {},
   "source": [
    "### Creating de CNN\n",
    "\n",
    "Resnet models has the format NCHW(Batch size, Channels, Height, Width), so that means the eg. (64, 3, 7, 7) refers to N=64, Channels=3, Height=7 and Width=7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc5c30da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.linen as nn\n",
    "import optax\n",
    "\n",
    "# We need this to hold the training state\n",
    "from flax.training.train_state import TrainState\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        conv = partial(self.conv, use_bias=False, dtype=self.dtype)\n",
    "        norm = partial(nn.BatchNorm,\n",
    "                       use_running_average=not train, \n",
    "                       momentum=0.9,\n",
    "                       epsilon=1e-5,\n",
    "                       dtype=self.dtype)\n",
    "        x = conv(self.num_filters, (7,7), (2,2),\n",
    "                 padding=[(3,3), (3,3)],\n",
    "                 name='conv_init')(x)\n",
    "        x = norm(name='bn_init')(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.max_pool(x, (3,3), strides=(2,2), padding='SAME')\n",
    "        for i, block_size in enumerate(self.stage_size):\n",
    "            for j in range(block_size):\n",
    "                strides = (2,2) if i > 0 and j == 0 else (1,1)\n",
    "                x = self.block_cls(self.num_filters * 2**i,\n",
    "                                   strides = strides,\n",
    "                                   conv = conv,\n",
    "                                   norm = norm,\n",
    "                                   act  = self.act)(x)\n",
    "        x = jnp.mean(x, axis=(1,2))\n",
    "        x = nn.Dense(self.num_classes, dtype=self.dtype)(x)\n",
    "        x = jnp.asarray(x, self.dtype)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f3a41",
   "metadata": {},
   "source": [
    "The function `__call__` was overwritten to be used internally by the Module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b088f777",
   "metadata": {},
   "source": [
    "### Evaluation Function\n",
    "Next we define a function to evaluate the entire model and summarize the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57775346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(params, test_ds):\n",
    "    metrics = eval_step(params, test_ds)\n",
    "    metrics = jax.device_get(metrics)\n",
    "    summary = jax.tree_map(lambda x: x.item(), metrics)\n",
    "    return summary['loss'], summary['accuracy']\n",
    "def eval_model(params, test_ds):\n",
    "    metrics = eval_step(params, test_ds)\n",
    "    metrics = jax.device_get(metrics)\n",
    "    summary = jax.tree_map(lambda x: x.item(), metrics)\n",
    "    return summary['loss'], summary['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ef0d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6307cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(rng, learning_rate, momentum):\n",
    "    # Instantiate model\n",
    "    cnn = ResNet18()\n",
    "    # Initialize parameters\n",
    "    params = cnn.init(rng, jnp.ones([1, 28, 28, 1]))['params']\n",
    "    # Instantiate optimizer\n",
    "    tx = optax.sgd(learning_rate, momentum)\n",
    "    # Instantiate train state\n",
    "    return TrainState.create(apply_fn=cnn.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "714960ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "\"ResNet18\" object has no attribute \"conv\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m      7\u001b[0m momentum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m\n\u001b[0;32m----> 8\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_train_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_rng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(jax\u001b[38;5;241m.\u001b[39mtree_map(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mshape, state\u001b[38;5;241m.\u001b[39mparams))\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36mcreate_train_state\u001b[0;34m(rng, learning_rate, momentum)\u001b[0m\n\u001b[1;32m      3\u001b[0m cnn \u001b[38;5;241m=\u001b[39m ResNet18()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize parameters\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Instantiate optimizer\u001b[39;00m\n\u001b[1;32m      7\u001b[0m tx \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39msgd(learning_rate, momentum)\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "File \u001b[0;32m/usr/lib64/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mResNet18.__call__\u001b[0;34m(self, x, train)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;129m@nn\u001b[39m\u001b[38;5;241m.\u001b[39mcompact\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, train: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 12\u001b[0m     conv \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m, use_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     13\u001b[0m     norm \u001b[38;5;241m=\u001b[39m partial(nn\u001b[38;5;241m.\u001b[39mBatchNorm,\n\u001b[1;32m     14\u001b[0m                    use_running_average\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m train, \n\u001b[1;32m     15\u001b[0m                    momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m,\n\u001b[1;32m     16\u001b[0m                    epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m,\n\u001b[1;32m     17\u001b[0m                    dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m conv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_filters, (\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m7\u001b[39m), (\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     19\u001b[0m              padding\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m)],\n\u001b[1;32m     20\u001b[0m              name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv_init\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/flax/linen/module.py:717\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    715\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[name]\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    718\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: \"ResNet18\" object has no attribute \"conv\""
     ]
    }
   ],
   "source": [
    "# Create random number generator\n",
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "\n",
    "# Create train state\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "state = create_train_state(init_rng, learning_rate, momentum)\n",
    "\n",
    "print(jax.tree_map(lambda x: x.shape, state.params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
